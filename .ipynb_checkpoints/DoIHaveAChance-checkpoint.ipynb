{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column met_o had values 1/2. It needs to be changed to 0/1.\n",
    "df = pd.read_csv('./data_for_matrix.csv')\n",
    "df['met_o'] = df['met_o'].apply(lambda x: x - 1)\n",
    "df.to_csv('data_for_matrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can see code that prepares data for the basic matrix factorization.\n",
    "Here in the base matrix we only have information about match. So we need a set of vectors, where each vector describes each date (holds both ids and information about match).\n",
    "\n",
    "Task will requite two base matrices.\n",
    "1. Matrix where men are \"users\" and women are \"products\". It will then be used to recommend women to men because matrix will say what's the predicted rating of a woman in eyes of man. Basically it will answer the question: **\"How likely is that a man will like a woman?\"**. Let's call this matrix/data frame **\"men_like_women\"**.\n",
    "1. Matrix where women are \"users\" and men are \"products\". It will then be used to recommend men to women because matrix will say what's the predicted rating of a man in eyes of woman. Basically it will answer the question: **\"How likely is that a woman will like a man?\"**. Let's call this matrix/data frame **\"women_like_men\"**.\n",
    "\n",
    "Why such analogies? It may help to understand how do this human relations task translates into recommender systems world.\n",
    "\n",
    "These matrices will be used to train models (with matrix factorization) which will then be saved into csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "men_like_women_df:\n",
      "       id  pid  match\n",
      "0      11    1    0.0\n",
      "1      11    2    0.0\n",
      "2      11    3    0.0\n",
      "3      11    4    0.0\n",
      "4      11    5    0.0\n",
      "...   ...  ...    ...\n",
      "4179  552  526    0.0\n",
      "4180  552  527    0.0\n",
      "4181  552  528    0.0\n",
      "4182  552  529    0.0\n",
      "4183  552  530    0.0\n",
      "\n",
      "[4184 rows x 3 columns]\n",
      "\n",
      "women_like_men_df:\n",
      "       id  pid  match\n",
      "0       1   11    0.0\n",
      "1       1   12    0.0\n",
      "2       1   13    1.0\n",
      "3       1   14    1.0\n",
      "4       1   15    1.0\n",
      "...   ...  ...    ...\n",
      "4179  530  548    0.0\n",
      "4180  530  549    0.0\n",
      "4181  530  550    0.0\n",
      "4182  530  551    0.0\n",
      "4183  530  552    0.0\n",
      "\n",
      "[4184 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split into vectors, let's have two matrices as describes above.\n",
    "base_df = pd.read_csv('./data_for_matrix.csv')\n",
    "men_like_women_data = []\n",
    "women_like_men_data = []\n",
    "\n",
    "for _, row in base_df.iterrows():\n",
    "    vector = {\n",
    "        'id': int(row['iid']),\n",
    "        'pid': int(row['pid']),\n",
    "        'match': row['match'],\n",
    "    }\n",
    "    if row['gender'] == 0:\n",
    "        women_like_men_data.append(vector)\n",
    "    else:\n",
    "        men_like_women_data.append(vector)\n",
    "\n",
    "men_like_women_df = pd.DataFrame(men_like_women_data)\n",
    "women_like_men_df = pd.DataFrame(women_like_men_data)\n",
    "\n",
    "print(\"men_like_women_df:\")\n",
    "print(men_like_women_df)\n",
    "print(\"\\nwomen_like_men_df:\")\n",
    "print(women_like_men_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create matrix factorization models\n",
    "\n",
    "We will create and train 4 base MF (matrix factorization) models:\n",
    "1. without bias and uniform (0, 0.2) weight initialization,\n",
    "2. without bias and xavier initialization,\n",
    "3. with bias and uniform (0, 0.2) weight initialization,\n",
    "4. with bias and xavier initialization,\n",
    "\n",
    "For each model will do a cross validation to learn the best hyperparameters and then we will compare the results and choose the best model.\n",
    "\n",
    "Some general explanations for models:\n",
    "* Models are train on only one batch because our data set is rather small.\n",
    "\n",
    "Good reading resource: https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78\n",
    "\n",
    "### First matrix factorization without bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with without xavier weights are:\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.1861, 0.0885, 0.0608],\n",
      "        [0.1417, 0.0768, 0.0050],\n",
      "        [0.0480, 0.1489, 0.1733],\n",
      "        [0.1277, 0.1798, 0.1219],\n",
      "        [0.1134, 0.1013, 0.1369],\n",
      "        [0.0137, 0.0563, 0.0562],\n",
      "        [0.1608, 0.0815, 0.0350],\n",
      "        [0.1816, 0.0749, 0.0309],\n",
      "        [0.0133, 0.1318, 0.0419],\n",
      "        [0.1030, 0.1421, 0.0741]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0149, 0.0588, 0.0011],\n",
      "        [0.0408, 0.1497, 0.0595],\n",
      "        [0.1890, 0.0965, 0.1531],\n",
      "        [0.0264, 0.0316, 0.0716],\n",
      "        [0.0129, 0.0800, 0.1334],\n",
      "        [0.1688, 0.1328, 0.0370],\n",
      "        [0.1979, 0.0643, 0.0349],\n",
      "        [0.0506, 0.0487, 0.1346],\n",
      "        [0.0148, 0.1426, 0.0773],\n",
      "        [0.1018, 0.0442, 0.1616]], requires_grad=True)\n",
      "\n",
      "\n",
      " ====================\n",
      "\n",
      "\n",
      "Model with with xavier weights are:\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.1621,  0.3820, -0.5530],\n",
      "        [-0.5206, -0.4121,  0.0596],\n",
      "        [ 0.6712, -0.0840, -0.1511],\n",
      "        [ 0.5221, -0.2019, -0.5928],\n",
      "        [ 0.5327, -0.1334,  0.4149],\n",
      "        [ 0.5692,  0.6244,  0.5838],\n",
      "        [-0.4908,  0.6188,  0.4765],\n",
      "        [ 0.0196,  0.2402,  0.0305],\n",
      "        [ 0.0829,  0.1049, -0.0428],\n",
      "        [-0.0847, -0.1915,  0.5459]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1590,  0.5998, -0.2620],\n",
      "        [ 0.5066,  0.6356,  0.2281],\n",
      "        [ 0.2614,  0.3552, -0.0309],\n",
      "        [-0.3007,  0.6478,  0.1181],\n",
      "        [ 0.1645,  0.3585, -0.2995],\n",
      "        [-0.4891,  0.1741, -0.1519],\n",
      "        [-0.5220, -0.5535,  0.2098],\n",
      "        [ 0.4870, -0.1299, -0.0653],\n",
      "        [ 0.4788,  0.0797,  0.3931],\n",
      "        [ 0.2886,  0.1597, -0.1125]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MatrixFactorizationWithoutBiasNoXavier(nn.Module):\n",
    "    def __init__(self, num_people, num_partners, emb_size=100):\n",
    "        super(MatrixFactorizationWithoutBiasNoXavier, self).__init__()\n",
    "        self.person_emb = nn.Embedding(num_people, emb_size)\n",
    "        self.partner_emb = nn.Embedding(num_partners, emb_size)\n",
    "        self.person_emb.weight.data.uniform_(0,0.2)\n",
    "        self.partner_emb.weight.data.uniform_(0,0.2)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        u = person_emb(u)\n",
    "        v = partner_emb(v)\n",
    "        # calculate dot product\n",
    "        # u*v is a element wise vector multiplication\n",
    "        return torch.sigmoid((u*v).sum(1))\n",
    "    \n",
    "    \n",
    "class MatrixFactorizationWithoutBiasXavier(nn.Module):\n",
    "    def __init__(self, num_people, num_partners, emb_size=100):\n",
    "        super(MatrixFactorizationWithoutBiasXavier, self).__init__()\n",
    "        self.person_emb = nn.Embedding(num_people, emb_size)\n",
    "        self.partner_emb = nn.Embedding(num_partners, emb_size)\n",
    "        torch.nn.init.xavier_uniform_(self.person_emb.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.partner_emb.weight)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        u = person_emb(u)\n",
    "        v = partner_emb(v)\n",
    "        # calculate dot product\n",
    "        # u*v is a element wise vector multiplication\n",
    "        return torch.sigmoid((u*v).sum(1))\n",
    "\n",
    "    \n",
    "# Example small models demonstrating weights\n",
    "example_model_no_xavier = MatrixFactorizationWithoutBiasNoXavier(10, 10, 3)\n",
    "example_model_xavier = MatrixFactorizationWithoutBiasXavier(10, 10, 3)\n",
    "print(\"Model with without xavier weights are:\\n\")\n",
    "for p in example_model_no_xavier.parameters():\n",
    "    print(p)\n",
    "print('\\n\\n', '='*20)\n",
    "print(\"\\n\\nModel with with xavier weights are:\\n\")\n",
    "for p in example_model_xavier.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First matrix factorization without bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with without xavier weights are:\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.1099, 0.1143, 0.0984],\n",
      "        [0.0748, 0.0337, 0.1018],\n",
      "        [0.1570, 0.1868, 0.0697],\n",
      "        [0.0471, 0.0729, 0.1599],\n",
      "        [0.1154, 0.0048, 0.0347],\n",
      "        [0.1226, 0.0631, 0.1086],\n",
      "        [0.1896, 0.0831, 0.1888],\n",
      "        [0.0768, 0.1468, 0.0677],\n",
      "        [0.0404, 0.1035, 0.0984],\n",
      "        [0.1422, 0.1440, 0.1245]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0098],\n",
      "        [ 0.0077],\n",
      "        [ 0.0027],\n",
      "        [ 0.0097],\n",
      "        [-0.0001],\n",
      "        [ 0.0093],\n",
      "        [-0.0071],\n",
      "        [ 0.0062],\n",
      "        [-0.0079],\n",
      "        [ 0.0015]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1820, 0.0942, 0.1919],\n",
      "        [0.0729, 0.1180, 0.0981],\n",
      "        [0.0676, 0.0867, 0.1336],\n",
      "        [0.0413, 0.0376, 0.1388],\n",
      "        [0.0413, 0.1409, 0.0168],\n",
      "        [0.1722, 0.0466, 0.1913],\n",
      "        [0.1174, 0.1423, 0.1985],\n",
      "        [0.0540, 0.1160, 0.1903],\n",
      "        [0.0906, 0.1192, 0.0544],\n",
      "        [0.1441, 0.1245, 0.0145]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0064],\n",
      "        [-0.0009],\n",
      "        [ 0.0020],\n",
      "        [ 0.0092],\n",
      "        [ 0.0099],\n",
      "        [-0.0029],\n",
      "        [-0.0083],\n",
      "        [ 0.0021],\n",
      "        [-0.0081],\n",
      "        [-0.0040]], requires_grad=True)\n",
      "\n",
      "\n",
      " ====================\n",
      "\n",
      "\n",
      "Model with with xavier weights are:\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.1656, 0.1181, 0.0873],\n",
      "        [0.0634, 0.1618, 0.0926],\n",
      "        [0.1018, 0.1287, 0.0130],\n",
      "        [0.1493, 0.1374, 0.1605],\n",
      "        [0.1841, 0.1834, 0.0596],\n",
      "        [0.1996, 0.1683, 0.1477],\n",
      "        [0.1030, 0.1528, 0.1222],\n",
      "        [0.0395, 0.1779, 0.1519],\n",
      "        [0.1373, 0.1831, 0.1676],\n",
      "        [0.1185, 0.1310, 0.0276]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0037],\n",
      "        [-0.0031],\n",
      "        [ 0.0023],\n",
      "        [-0.0010],\n",
      "        [-0.0070],\n",
      "        [-0.0094],\n",
      "        [-0.0057],\n",
      "        [ 0.0052],\n",
      "        [ 0.0078],\n",
      "        [ 0.0022]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1182, 0.0240, 0.0816],\n",
      "        [0.1464, 0.1020, 0.0311],\n",
      "        [0.1129, 0.0204, 0.1600],\n",
      "        [0.0609, 0.1927, 0.1512],\n",
      "        [0.1542, 0.1788, 0.1623],\n",
      "        [0.1858, 0.0619, 0.1654],\n",
      "        [0.0918, 0.1272, 0.0182],\n",
      "        [0.1405, 0.1666, 0.0272],\n",
      "        [0.0323, 0.1873, 0.1955],\n",
      "        [0.1831, 0.0604, 0.0880]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0038],\n",
      "        [-0.0046],\n",
      "        [-0.0023],\n",
      "        [ 0.0069],\n",
      "        [-0.0053],\n",
      "        [-0.0008],\n",
      "        [-0.0012],\n",
      "        [ 0.0028],\n",
      "        [-0.0034],\n",
      "        [ 0.0050]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MatrixFactorizationWithBiasNoXavier(nn.Module):\n",
    "    def __init__(self, num_people, num_partners, emb_size=100):\n",
    "        super(MatrixFactorizationWithBiasNoXavier, self).__init__()\n",
    "        self.person_emb = nn.Embedding(num_people, emb_size)\n",
    "        self.person_bias = nn.Embedding(num_people, 1)\n",
    "        self.partner_emb = nn.Embedding(num_partners, emb_size)\n",
    "        self.parnter_bias = nn.Embedding(num_partners, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.person_emb.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.partner_emb.weight)\n",
    "        self.person_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.parnter_bias.weight.data.uniform_(-0.01,0.01)\n",
    "            \n",
    "    def forward(self, u, v):\n",
    "        u = person_emb(u)\n",
    "        v = partner_emb(v)\n",
    "        # calculate dot product\n",
    "        # u*v is a element wise vector multiplication\n",
    "        return torch.sigmoid((u*v).sum(1))\n",
    "    \n",
    "    \n",
    "class MatrixFactorizationWithBiasNoXavier(nn.Module):\n",
    "    def __init__(self, num_people, num_partners, emb_size=100):\n",
    "        super(MatrixFactorizationWithBiasNoXavier, self).__init__()\n",
    "        self.person_emb = nn.Embedding(num_people, emb_size)\n",
    "        self.person_bias = nn.Embedding(num_people, 1)\n",
    "        self.partner_emb = nn.Embedding(num_partners, emb_size)\n",
    "        self.parnter_bias = nn.Embedding(num_partners, 1)\n",
    "        self.person_emb.weight.data.uniform_(0,0.2)\n",
    "        self.partner_emb.weight.data.uniform_(0,0.2)\n",
    "        self.person_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.parnter_bias.weight.data.uniform_(-0.01,0.01)\n",
    "            \n",
    "    def forward(self, u, v):\n",
    "        u = person_emb(u)\n",
    "        v = partner_emb(v)\n",
    "        # calculate dot product\n",
    "        # u*v is a element wise vector multiplication\n",
    "        return torch.sigmoid((u*v).sum(1))\n",
    "    \n",
    "\n",
    "# Example small models demonstrating weights\n",
    "example_model_no_xavier = MatrixFactorizationWithBiasNoXavier(10, 10, 3)\n",
    "example_model_xavier = MatrixFactorizationWithBiasNoXavier(10, 10, 3)\n",
    "print(\"Model with without xavier weights are:\\n\")\n",
    "for p in example_model_no_xavier.parameters():\n",
    "    print(p)\n",
    "print('\\n\\n', '='*20)\n",
    "print(\"\\n\\nModel with with xavier weights are:\\n\")\n",
    "for p in example_model_xavier.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
